{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d6482bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\n",
      "Verbs: ['start', 'work', 'drive', 'take', 'tell', 'shake', 'turn', 'be', 'talk', 'say']\n",
      "Sebastian Thrun PERSON\n",
      "Google ORG\n",
      "2007 DATE\n",
      "American NORP\n",
      "Thrun GPE\n",
      "earlier this week DATE\n"
     ]
    }
   ],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a02d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## disable part-of-speech tagging and lemmatization\n",
    "\n",
    "## to disable part of speech tagging and lemmatization\n",
    "# Note: English doesn't include a morphologizer\n",
    "# nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "# nlp = spacy.load(\"en_core_web_trf\", disable=[\"tagger\", \"attribute_ruler\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37ae3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the senter and disable parser\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.disable_pipe(\"parser\")\n",
    "# nlp.enable_pipe(\"senter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7294890",
   "metadata": {},
   "outputs": [],
   "source": [
    "## switch from rule-based to lookup lemmatization\n",
    "## For the Dutch, English, French, Greek, Macedonian, Norwegian and Spanish pipelines, \n",
    "## you can switch from the default rule-based lemmatizer to a lookup lemmatizer:\n",
    "## Requirements: pip install spacy-lookups-data\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.remove_pipe(\"lemmatizer\")\n",
    "# nlp.add_pipe(\"lemmatizer\", config={\"mode\": \"lookup\"}).initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e4189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Disable everything except NER\n",
    "## For the non-transformer models, the ner component is independent, so you can disable everything else\n",
    "# nlp = spacy.load(\"en_core_web_sm\", disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cd7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in the transformer models, ner listens to the transformer component, \n",
    "## so you can disable all components related tagging, parsing, and lemmatization.\n",
    "# nlp = spacy.load(\"en_core_web_trf\", disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de57082",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Move NER to the end of the pipeline\n",
    "##For access to POS and LEMMA features in an entity_ruler, \n",
    "##move ner to the end of the pipeline after attribute_ruler and lemmatizer:\n",
    "\n",
    "## load without NER\n",
    "# nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "\n",
    "## source NER from the same pipeline package as the last component\n",
    "# nlp.add_pipe(\"ner\", source=spacy.load(\"en_core_web_sm\"))\n",
    "\n",
    "## insert the entity ruler\n",
    "# nlp.add_pipe(\"entity_ruler\", before=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949863a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL\n",
    "# # from spacy.pipeline.textcat_multilabel import DEFAULT_MULTI_TEXTCAT_MODEL\n",
    "\n",
    "# config = {\n",
    "#     'threshold': 0.5,\n",
    "#     'model': DEFAULT_SINGLE_TEXTCAT_MODEL,\n",
    "# }\n",
    "\n",
    "# model = nlp.add_pipe('textcat', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fd2c870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doc = nlp(\"this is sentence.\")\n",
    "# predicted = model(doc)\n",
    "# print(predicted)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a043da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add_label('pos')\n",
    "# model.add_label('neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a4e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.lang.en import English\n",
    "\n",
    "\n",
    "# nlp = English()\n",
    "# docs = nlp(text)\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22212220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = [w.text for w in docs]\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "667e1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sent = nlp.create_pipe('sentencizer')\n",
    "# nlp.add_pipe('sentencizer')\n",
    "# docs = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea7ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = nlp(text)\n",
    "# print(nlp.pipe_names)\n",
    "\n",
    "# sentences = [s.text for s in docs.sents]\n",
    "# print(len(sentences), sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a53ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sebastian, Thrun, started, working, self, -, driving, cars, Google, 2007, ,, people, outside, company, took, seriously, ., “, tell, senior, CEOs, major, American, car, companies, shake, hand, turn, away, worth, talking, ,, ”, said, Thrun, ,, interview, Recode, earlier, week, .]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "## remove stop_words\n",
    "clean = [w for w in doc if not w.is_stop]\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a969aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.add_pipe('lemmatizer')\n",
    "# lem = nlp(\"run runs ran running runners\")\n",
    "# _lem = [w.lemma_ for w in lem]\n",
    "# print(_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa5d0a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DET'),\n",
       " ('is', 'AUX'),\n",
       " ('really', 'ADV'),\n",
       " ('helpful', 'ADJ'),\n",
       " ('for', 'ADP'),\n",
       " ('quickly', 'ADV'),\n",
       " ('extracting', 'VERB'),\n",
       " ('information', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('text', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('since', 'SCONJ'),\n",
       " ('you', 'PRON'),\n",
       " ('can', 'AUX'),\n",
       " ('not', 'PART'),\n",
       " ('ca', 'AUX'),\n",
       " (\"n't\", 'PART'),\n",
       " ('quickly', 'ADV'),\n",
       " ('pick', 'VERB'),\n",
       " ('out', 'ADP'),\n",
       " ('important', 'ADJ'),\n",
       " ('topics', 'NOUN'),\n",
       " ('or', 'CCONJ'),\n",
       " ('indentify', 'VERB'),\n",
       " ('key', 'ADJ'),\n",
       " ('sections', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('text', 'NOUN')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Par-of-speech (pos) tagging\n",
    "\n",
    "## noun, adj identified as an object, verb as action\n",
    "\n",
    "from spacy import displacy\n",
    "# import en_core_web_sm\n",
    "\n",
    "# nlp = en_core_web_sm.load()\n",
    "\n",
    "docs = nlp(\"This is really helpful for quickly extracting information from text,\" \n",
    "           \"since you cannot can't quickly pick out important topics or indentify key sections of text\")\n",
    "\n",
    "# entities = [(i, i.label_, i.label) for i in docs.ents]\n",
    "entities = [(w.text, w.pos_) for w in docs]\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22ff31f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 'be'),\n",
       " ('extracting', 'extract'),\n",
       " ('can', 'can'),\n",
       " ('ca', 'ca'),\n",
       " ('pick', 'pick'),\n",
       " ('indentify', 'indentify')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm = [(w.text, w.lemma_) for w in docs if w.pos_.startswith('V') or w.pos_ == 'AUX']\n",
    "lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fbbda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(New York City, 'GPE', 384),\n",
       " (Tuesday, 'DATE', 391),\n",
       " (At least 285, 'CARDINAL', 397),\n",
       " (September, 'DATE', 391),\n",
       " (Brooklyn, 'GPE', 384),\n",
       " (four, 'CARDINAL', 397),\n",
       " (Zip, 'PERSON', 380),\n",
       " (Bill de Blasio, 'PERSON', 380),\n",
       " (Tuesday, 'DATE', 391),\n",
       " (Orthodox, 'NORP', 381),\n",
       " (6 months old, 'DATE', 391),\n",
       " (up to $1,000, 'MONEY', 394)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## entity Detection, tagging words or n-gram of words with entity recognition \n",
    "## such as places, people, organizations,...\n",
    "## language input string text, \n",
    "\n",
    "nytimes= nlp(u\"\"\"New York City on Tuesday declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases.\n",
    "\n",
    "At least 285 people have contracted measles in the city since September, mostly in Brooklyn’s Williamsburg neighborhood. The order covers four Zip codes there, Mayor Bill de Blasio (D) said Tuesday.\n",
    "\n",
    "The mandate orders all unvaccinated people in the area, including a concentration of Orthodox Jews, to receive inoculations, including for children as young as 6 months old. Anyone who resists could be fined up to $1,000.\"\"\")\n",
    "\n",
    "entities=[(i, i.label_, i.label) for i in nytimes.ents]\n",
    "entities\n",
    "\n",
    "## GPE: specific location, CARDINAL: important number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1960589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York City\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases.</br></br>\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    At least 285\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " people have contracted measles in the city since \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    September\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", mostly in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brooklyn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "’s Williamsburg neighborhood. The order covers \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    four\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zip\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " codes there, Mayor \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bill de Blasio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " (D) said \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</br></br>The mandate orders all unvaccinated people in the area, including a concentration of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Orthodox\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " Jews, to receive inoculations, including for children as young as \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    6 months old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". Anyone who resists could be fined \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    up to $1,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## display visualize output text with colored entities (style='ent')\n",
    "displacy.render(nytimes, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bba84da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw: pursuit, root: pursuit, dependency: pobj, header: In\n",
      "raw: a wall, root: wall, dependency: pobj, header: of\n",
      "raw: President Trump, root: Trump, dependency: nsubj, header: ran\n"
     ]
    }
   ],
   "source": [
    "## Dependency Parsing, \n",
    "## determine the meaning of a sentence by how constructed itself based on individual words\n",
    "docp = nlp (\" In pursuit of a wall, President Trump ran into one.\")\n",
    "\n",
    "for chunk in docp.noun_chunks:\n",
    "   print(f'raw: {chunk.text}, root: {chunk.root.text}, dependency: {chunk.root.dep_}, header: {chunk.root.head.text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f44ae502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f18f08408aaa4e81b7a24aba333d38e0-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"> </tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">In</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">pursuit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">wall,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">President</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Trump</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">ran</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">into</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">one.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-1\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M215.0,266.5 L223.0,254.5 207.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-7\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f18f08408aaa4e81b7a24aba333d38e0-0-9\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f18f08408aaa4e81b7a24aba333d38e0-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1790.0,266.5 L1798.0,254.5 1782.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docp, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9157e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n",
      "[-0.462305   -0.97013503 -0.3536405   0.28740364 -0.01573728 -0.24513936\n",
      " -1.215326   -0.8796606  -0.33882028 -0.85366464  1.1009694  -0.40891293\n",
      "  0.22952707  0.32104927 -0.16520308  0.19346984  0.18104246 -0.25050682\n",
      " -0.86570626 -0.5158702   0.13842583 -1.1441295  -1.2371405  -0.31056306\n",
      " -0.77198493 -0.7328714   0.821449    0.46671125  0.46151486 -0.3285221\n",
      "  0.5737759   0.5633069   0.81746995 -0.1666174  -0.31984073  0.10492463\n",
      " -1.0577446   0.35842416  0.47972912 -0.29047596 -0.07571032  1.112559\n",
      " -0.21457072  1.0962675  -0.1150732   0.00683655  0.3471359   0.7762994\n",
      " -0.18421805 -0.4036425   0.42345917  0.25998825  0.43403518 -0.3259907\n",
      "  1.1417992  -0.21782616  0.6406765   0.25259757 -0.17306823 -0.4783872\n",
      "  0.89445263  0.16820912 -0.01807833  0.81608206 -0.42206132 -0.67849445\n",
      "  0.26927558 -0.5631349   0.6785864   1.0213488   1.2156711   0.1348517\n",
      " -0.53032076 -0.13513318  0.05589192 -0.2488123   0.3784064  -0.9752467\n",
      " -0.5351178   0.12411818  0.12952325  0.01232275 -0.50991184  0.6610786\n",
      " -0.86778444  0.00903399  0.5004437  -0.63288045  0.75803006 -0.28494287\n",
      " -1.0945169   0.6785468   0.3368305   0.9685489  -0.7742628   0.30807123]\n"
     ]
    }
   ],
   "source": [
    "## word vector space representation\n",
    "\n",
    "## A word vector is a numeric representation of a word that commuicates its relationship to other words.\n",
    "\n",
    "mango = nlp(u'mango')\n",
    "print(mango.vector.shape)\n",
    "print(mango.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444845fc",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "Combination models, sklearn, spacy, supervised classification, prediction label (feedback)\n",
    "![text classification](data/text_classification.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7738c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a357fe39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       date         variation  \\\n",
       "0       5  31-Jul-18  Charcoal Fabric    \n",
       "1       5  31-Jul-18  Charcoal Fabric    \n",
       "2       4  31-Jul-18    Walnut Finish    \n",
       "3       5  31-Jul-18  Charcoal Fabric    \n",
       "4       5  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \n",
       "0                                      Love my Echo!         1  \n",
       "1                                          Loved it!         1  \n",
       "2  Sometimes while playing a game, you can answer...         1  \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
       "4                                              Music         1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon = pd.read_csv('data/amazon_alexa.tsv', sep='\\t')\n",
    "df_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbe28ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   rating            3150 non-null   int64 \n",
      " 1   date              3150 non-null   object\n",
      " 2   variation         3150 non-null   object\n",
      " 3   verified_reviews  3150 non-null   object\n",
      " 4   feedback          3150 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 123.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3150, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_amazon.shape, df_amazon.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bce83e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2835,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(315,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "stop_words = STOP_WORDS\n",
    "\n",
    "def clean_tokens(topic):\n",
    "    \n",
    "    table = str.maketrans('', '', punctuation)\n",
    "    tokens = nlp(topic)\n",
    "    tokens = [w.lemma_ for w in tokens]\n",
    "    #tokens = [w.text for w in tokens]\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [w for w in tokens if len(w) > 1]\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "## customize transformer using Spacy\n",
    "class predictors(TransformerMixin):\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        tokens = [topic.strip().lower() for topic in X]\n",
    "        return tokens\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "#generate BoW matrix (word to matrix vector space) with spacy_tokenizer (clean_tokens) as tokenizer    \n",
    "bow_vector = CountVectorizer(tokenizer=clean_tokens, ngram_range=(1,1))\n",
    "\n",
    "#normalize word vector, and representation of word importance in the corpus.\n",
    "tfidf_vector = TfidfVectorizer(tokenizer=clean_tokens)\n",
    "\n",
    "# split train and test set\n",
    "X = df_amazon['verified_reviews']\n",
    "y = df_amazon['feedback']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.1)\n",
    "display(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21cdcd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x7f87a08c4d10>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(tokenizer=<function clean_tokens at 0x7f87a08b8c20>)),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## training with spacy \n",
    "classifier = LogisticRegression()\n",
    "pipe = Pipeline([('cleaner', predictors()),\n",
    "                ('vectorizer', bow_vector),\n",
    "                ('classifier', classifier)])\n",
    "\n",
    "pipe.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fa51fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.9301587301587302, precision= 0.9342105263157895, recall= 0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as m\n",
    "\n",
    "\n",
    "yhat = pipe.predict(Xtest)\n",
    "\n",
    "print(f'accuracy= {m.accuracy_score(ytest, yhat)}, precision= {m.precision_score(ytest, yhat)}, recall= {m.recall_score(ytest, yhat)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7210903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
